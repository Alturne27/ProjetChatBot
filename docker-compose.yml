services :
  chatbot-front:
    container_name: chatbot-front
    build:
      context: ./front-build/
      dockerfile: dev.Dockerfile
    env_file:
      - ./front-build/.env.local
    environment:
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - WDS_SOCKET_HOST=127.0.0.1

    volumes:
      - ./front-build:/app
      - chatbot_front_node_module:/app/node_modules
    restart: always
    ports:
      - 3000:3000
    networks:
      - chatbot-network
    depends_on:
      - chatbot-db

  chatbot-db:
    container_name: chatbot-db
    image: postgres

    env_file:
      - ./db-build/.env.database
    ports:
      - 5432:5432
    volumes:
     - ./pgdata:/var/lib/postgresql/data
    networks:
      - chatbot-network
    restart: unless-stopped
    
  chatbot-ollama:
    container_name: chatbot-ollama
    pull_policy: always
    image: ollama/ollama:latest
    tty: true
    ports:
      - 11434:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all 
              capabilities: [gpu]
    environment:
      OLLAMA_KEEP_ALIVE: -1
    volumes:
      - ./ollama-build/ollama:/root/.ollama
      - ./ollama-build/init.sh:/init.sh
      - ./ollama-build/Modelfile:/Modelfile
    networks:
      - chatbot-network
    restart: always
    entrypoint: ["/usr/bin/bash", "/init.sh"]

  chatbot-api:
    container_name : chatbot-api
    build:
      context: ./api-build/
      dockerfile: Dockerfile
    env_file:
      - ./api-build/.env.database
    ports:
      - 80:80
    volumes:
      - ./api-build/api:/app
      - ./api-build/data:/data
      - ./api-build/chroma-db:/chroma-db
    networks:
      - chatbot-network
    tty : true
    restart: always
    depends_on:
      - chatbot-front
      - chatbot-db
      - chatbot-ollama

networks:
  chatbot-network:
    driver: bridge

volumes:
  chatbot_front_node_module: