services:
  chatbot-front:
    container_name: chatbot-front
    build:
      context: ./front-build/
      dockerfile: dev.Dockerfile
    env_file:
      - ./front-build/.env.local
    environment:
      - CHOKIDAR_USEPOLLING=true
      - WATCHPACK_POLLING=true
      - WDS_SOCKET_HOST=127.0.0.1

    volumes:
      - ./front-build:/app
      - chatbot_front_node_module:/app/node_modules
    restart: always
    ports:
      - 3000:3000
    networks:
      - chatbot-network
    depends_on:
      chatbot-db:
        condition: service_healthy
      chatbot-ollama:
        condition: service_healthy

  chatbot-db:
    container_name: chatbot-db
    image: postgres

    env_file:
      - ./db-build/.env.database
    ports:
      - 5432:5432
    volumes:
      - ./pgdata:/var/lib/postgresql/data
    networks:
      - chatbot-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 2s
      retries: 5
      start_period: 5s
      timeout: 5s

  chatbot-ollama:
    container_name: chatbot-ollama
    pull_policy: always
    image: ollama/ollama:latest
    tty: true
    ports:
      - 11434:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      OLLAMA_KEEP_ALIVE: -1
    volumes:
      - ./ollama-build/ollama:/root/.ollama
      - ./ollama-build/init.sh:/init.sh
      - ./ollama-build/Modelfile:/Modelfile
    networks:
      - chatbot-network
    restart: unless-stopped
    entrypoint: ["/usr/bin/bash", "/init.sh"]
    healthcheck:
      test:
        - "CMD-SHELL"
        - |
          test -f /tmp/ollama_ready && \
          bash -c '</dev/tcp/localhost/11434'  # Checks if Ollama is accepting connections
      interval: 10s
      timeout: 10s
      retries: 100
      start_period: 10s

  chatbot-api:
    container_name: chatbot-api
    build:
      context: ./api-build/
      dockerfile: Dockerfile
    env_file:
      - ./api-build/.env.database
    ports:
      - 80:80
    volumes:
      - ./api-build/api:/app
      - ./api-build/data:/data
      - ./api-build/chroma-db:/chroma-db
    networks:
      - chatbot-network
    tty: true
    restart: unless-stopped
    depends_on:
      chatbot-db:
        condition: service_healthy
      chatbot-ollama:
        condition: service_healthy

networks:
  chatbot-network:
    driver: bridge

volumes:
  chatbot_front_node_module:
